<html>
  <head>
<title>Table of UNet runs</title>
</head>
<body>
<h1>Table of UNet runs</h1>

<h2>Explanation</h2>

<ul>
  <li><strong>Code base:</strong> "Old" refers to the code with pretrained weights. "New" refers to the code that evolved out of Bryan's version of the UNet.
  <li><strong>Resolution:</strong> "Low" refers to 320x320 pixels of 0.02 arcsec each. "High" refers to 640x640 pixels of 0.01 arcsec each.
  <li><strong>Channels:</strong> How many channels are in the first convolution block? All the rest of the numbers of channels are determined proportionally.
  <li><strong>True positive rates:</strong> What are the true positive rates corresponding to a false negative rate of 10%? The four numbers are for the mass bins in increasing order: 10^8-10^8.5, 10^8.5-10^9, 10^9-10^9.5, 10^9.5-10^10.
  <li><strong>Training images:</strong> We use 10^5 training images, unless otherwise stated.
  <li><strong>Dropout:</strong> Dropout is always 0% for the old code and 10% for the new code unless otherwise listed.
  <li><strong>Batch size:</strong> Batch size is always 8 unless otherwise noted.
</ul>

<h2>Table</h2>

<table>
  <tr>
    <th>UNet</th>
    <th>Code base</th>
    <th>Resolution</th>
    <th>Channels</th>
    <th>True positive rates</th>
    <th>Comments</th>
    <th>Loss curve</th>
  </tr>
  <tr>
    <td>Average pool</td>
    <td>New</td>
    <td>High</td>
    <td>64</td>
    <td>0.177, 0.397, 0.627, 0.829</td>
    <td>Effectively like a low-resolution UNet, except there's an extra average pooling layer at the beginning and upconvolution at the end. This was the first time we saw decent performance on the high resolution data.</td>
    <td><img src="imgs/loss_avgpool.png" width="300"></td>
  </tr>
  <tr>
    <td>Normal1</td>
    <td>New</td>
    <td>Low</td>
    <td>64</td>
    <td>0.189, 0.425, 0.661, 0.846</td>
    <td>Best performance on low resolution (compared to Old1 and Old3).</td>
    <td><img src="imgs/loss_normal1.png" width="300"></td>
  </tr>
  <tr>
    <td>Old1</td>
    <td>Old</td>
    <td>Low</td>
    <td>64</td>
    <td>0.156, 0.368, 0.614, 0.808</td>
    <td></td>
    <td><img src="imgs/loss_old1.png" width="300"></td>
  </tr>
  <tr>
    <td>Old2</td>
    <td>Old</td>
    <td>High</td>
    <td>64</td>
    <td>0.130, 0.285, 0.554, 0.740</td>
    <td></td>
    <td><img src="imgs/loss_old2.png" width="300"></td>
  </tr>
  <tr>
    <td>Old3</td>
    <td>Old</td>
    <td>Low</td>
    <td>32</td>
    <td>0.149, 0.345, 0.639, 0.848</td>
    <td></td>
    <td><img src="imgs/loss_old3.png" width="300"></td>
  </tr>
  <tr>
    <td>Old4</td>
    <td>Old</td>
    <td>High</td>
    <td>32</td>
    <td>0.210, 0.427, 0.654, 0.836</td>
    <td></td>
    <td><img src="imgs/loss_old4.png" width="300"></td>
  </tr>
  <tr>
    <!-- UNet 13 -->
    <td>Normal2</td>
    <td>New</td>
    <td>High</td>
    <td>64</td>
    <td>0.094, 0.155, 0.400, 0.639</td>
    <td>This one does especially poorly. Dropout 10%. Currently running again with dropout 20%.</td>
    <td><img src="imgs/loss_normal2.png" width="300"></td>
  </tr>

  <tr>
    <!-- UNet 9 -->
    <td>Normal3</td>
    <td>New</td>
    <td>High</td>
    <td>32</td>
    <td>0.197, 0.405, 0.625, 0.804</td>
    <td>The only difference from "Normal2" is we decreased the number of
    channels, and overfitting became much less of an issue. You can still
    clearly see overfitting, so we are also rerunning this with dropout
    20%.</td>
    <td><img src="imgs/loss_normal3.png" width="300"></td>
  </tr>

  <tr>
    <td>500000 data</td>
    <td>New</td>
    <td>High</td>
    <td>32</td>
    <td>0.223, 0.477, 0.697, 0.870</td>
    <td>This is an older run than the rest on this list, started before we made
    the matching high and low resolution datasets. Batch size 4 instead of 8.
    Ran 3 epochs before timing out. Trained on 500,000 images instead of
    100,000. Originally I had visualized and constructed the ROC curve with the
    wrong normalization, so I didn't think it was working.</td>
    <td><img src="imgs/loss_500000data.png" width="300"></td>
  </tr>

  <tr>
    <td>10^6 data</td>
    <td>New</td>
    <td>High</td>
    <td>64</td>
    <td>0.148, 0.383, 0.650, 0.827</td>
    <td>Like Normal2 but more data. Ran 5 epochs after timing out after 3 days.</td>
    <td><img src="imgs/loss_1e6data.png" width="300"></td>
  </tr>

  <tr>
    <td>More channels</td>
    <td>New</td>
    <td>High</td>
    <td>128</td>
    <td>0.118, 0.191, 0.446, 0.682</td>
    <td>Like Normal2 or Normal3, but testing if even more channels improves performance. This model also did poorly.</td>
    <td><img src="imgs/loss_bigker10.png" width="300"></td>
  </tr>

    <tr>
    <td>Kernel 5</td>
    <td>New</td>
    <td>High</td>
    <td>64</td>
    <td>0.116, 0.165, 0.447, 0.684</td>
    <td>Like Normal2 but testing if a larger kernel size improves performance. This model also did poorly.</td>
    <td><img src="imgs/loss_bigker11.png" width="300"></td>
    </tr>

  <tr>
    <td>Larger batch</td>
    <td>New</td>
    <td>High</td>
    <td>64</td>
    <td>0.191, 0.435, 0.654, 0.830</td>
    <td>Like Normal2 but testing if a batch size of 16 instead of 8 would improve performance.</td>
    <td><img src="imgs/loss_bigker12.png" width="300"></td>
  </tr>
  
  
</table>

</body>
</html>
